{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2227644,"sourceType":"datasetVersion","datasetId":1338117},{"sourceId":7622661,"sourceType":"datasetVersion","datasetId":4440267}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing the required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-14T17:55:20.001045Z","iopub.execute_input":"2024-02-14T17:55:20.001548Z","iopub.status.idle":"2024-02-14T17:55:21.176716Z","shell.execute_reply.started":"2024-02-14T17:55:20.001511Z","shell.execute_reply":"2024-02-14T17:55:21.175161Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Generating a corpus of words with which we can train our model\n\n# Dataset from which we will generate our word corpus\nword_corpus_df = pd.read_csv(\"/kaggle/input/part-of-speech-tagging/words_pos.csv\")\nword_corpus_df.drop(columns = [\"Unnamed: 0\", \"pos_tag\"], inplace = True)\nprint(word_corpus_df.shape)\nword_corpus_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:55:21.178509Z","iopub.execute_input":"2024-02-14T17:55:21.179838Z","iopub.status.idle":"2024-02-14T17:55:21.619797Z","shell.execute_reply.started":"2024-02-14T17:55:21.179797Z","shell.execute_reply":"2024-02-14T17:55:21.618352Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(370100, 1)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"     word\n0      aa\n1     aaa\n2     aah\n3   aahed\n4  aahing\n5    aahs\n6     aal\n7   aalii\n8  aaliis\n9    aals","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aaa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aah</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aahed</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aahing</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>aahs</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aal</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>aalii</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>aaliis</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>aals</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Creation of the target dataset that our algoirthms will be performing upon\n\ndef create_target_dataset(df, size):\n    \n    letters = \"abcdefghijklmnopqrstuvwxyz\"\n    words_string = \"\"\n    \n    # Creating \"size\" random words\n    for i in range(size):\n        \n        # Selecting a random word from the word corpus\n        random_word_index = random.randint(0, len(df) - 1)\n        random_word = df.loc[random_word_index, 'word']\n        \n        # Determining number of modifications to be done on the randomly selected word\n        random_number_of_letter_modifications = 1\n        if len(random_word) > 2:\n            random_number_of_letter_modifications = random.randint(1, min(int(len(random_word) / 2), 2))\n\n        changed_indices = []\n        random_word_list = list(random_word)\n        \n        # Modifying the randomly selected word\n        for _ in range(random_number_of_letter_modifications):\n            random_word_index = random.randint(0, len(random_word_list) - 1)\n            while random_word_index in changed_indices:\n                random_word_index = random.randint(0, len(random_word_list) - 1)\n            random_word_index_letter_change = random.choice(letters)\n            random_word_list[random_word_index] = random_word_index_letter_change\n\n        random_word = ''.join(random_word_list)\n        words_string = words_string + random_word + \" \"\n\n    return words_string","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:55:21.672778Z","iopub.execute_input":"2024-02-14T17:55:21.673248Z","iopub.status.idle":"2024-02-14T17:55:21.684798Z","shell.execute_reply.started":"2024-02-14T17:55:21.673211Z","shell.execute_reply":"2024-02-14T17:55:21.682865Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"words_string_levenshtein_distance = create_target_dataset(word_corpus_df, 1000)\nwords_list_levenshtein_distance = words_string_levenshtein_distance.split()\nprint(len(words_list_levenshtein_distance))\n\nwords_string_symspellpy = create_target_dataset(word_corpus_df, 150000)\nwords_list_symspellpy = words_string_symspellpy.split()\nprint(len(words_list_symspellpy))\n\nwords_string_bk_tree = create_target_dataset(word_corpus_df, 1000)\nwords_list_bk_tree = words_string_bk_tree.split()\nprint(len(words_list_bk_tree))","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:55:23.224562Z","iopub.execute_input":"2024-02-14T17:55:23.225199Z","iopub.status.idle":"2024-02-14T17:55:37.954578Z","shell.execute_reply.started":"2024-02-14T17:55:23.225157Z","shell.execute_reply":"2024-02-14T17:55:37.953088Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"1000\n150000\n1000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Levenshtein Distance Approach","metadata":{}},{"cell_type":"code","source":"# Method to calculate levenshtein distance (ld) between two words.\n# Example: ld between \"aba\" and \"ab\" is 1, ld between \"abc\" and \"aed\" is 2.\ndef levenshtein_distance(word1, word2):\n    m, n = len(word1), len(word2)\n    \n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n    \n    for i in range(m + 1):\n        dp[i][0] = i\n    for j in range(n + 1):\n        dp[0][j] = j\n    \n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if word1[i - 1] == word2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = min(dp[i - 1][j - 1], dp[i][j - 1], dp[i - 1][j]) + 1\n    \n    return dp[m][n]","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:55:37.957288Z","iopub.execute_input":"2024-02-14T17:55:37.958064Z","iopub.status.idle":"2024-02-14T17:55:37.972177Z","shell.execute_reply.started":"2024-02-14T17:55:37.958023Z","shell.execute_reply":"2024-02-14T17:55:37.970519Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Method to use levenshtein distance across the entire word corpus.\n# Determines the best suited word to substitute the input_word with.\ndef correct_spelling_levenshtein_distance(input_word, word_corpus_df):\n    min_distance = float('inf')\n    best_correction = input_word\n    \n    # Finding words that have a absolute difference of length 2 from input_word\n    possible_correct_words_corpus = []\n    for word in word_corpus_df[\"word\"]:\n        if((len(word) >= max(len(input_word) - 2, 0)) and (len(word) <= min(len(input_word) + 2, 31))):\n            possible_correct_words_corpus.append(word)\n    \n    # Calculating levenshtein distance between input_word and our possible words\n    # Choosing the word with shortest levenshtein distance wrt input_word\n    for word in possible_correct_words_corpus:\n        distance = levenshtein_distance(input_word, word)\n        \n        if(distance < min_distance):\n            min_distance = distance\n            best_correction = word\n           \n        if(distance == min_distance):\n            if(len(word) == len(input_word)):\n                best_correction = word\n            \n    return best_correction","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:55:37.973931Z","iopub.execute_input":"2024-02-14T17:55:37.974320Z","iopub.status.idle":"2024-02-14T17:55:37.992362Z","shell.execute_reply.started":"2024-02-14T17:55:37.974289Z","shell.execute_reply":"2024-02-14T17:55:37.990471Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Applying our Levenshtein Distance Approach to all 150000 words\nfrom datetime import datetime\n\nstart_time = datetime.now()\nfor word_index in range(10):\n    words_list_levenshtein_distance[word_index] = correct_spelling_levenshtein_distance(words_list_levenshtein_distance[word_index], word_corpus_df)\n    \nend_time = datetime.now()\ncounter = int(len(words_list_levenshtein_distance) / 1000)\n\nprint(\"Average Time to Process 1000 Words: \" + str((end_time - start_time) / counter))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SymSpellPy Approach","metadata":{}},{"cell_type":"code","source":"pip install symspellpy","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:55:37.995843Z","iopub.execute_input":"2024-02-14T17:55:37.998273Z","iopub.status.idle":"2024-02-14T17:55:54.055990Z","shell.execute_reply.started":"2024-02-14T17:55:37.998213Z","shell.execute_reply":"2024-02-14T17:55:54.054284Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: symspellpy in /opt/conda/lib/python3.10/site-packages (6.7.7)\nRequirement already satisfied: editdistpy>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from symspellpy) (0.1.3)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Using Norvig's text dataset to generate frequencies of all words and creating a Word Dictionary\n# Adding words from our word corpus that are not present in the Word Dictionary\nimport re\nfrom collections import Counter\n\ndef words(text): return re.findall(r'\\w+', text.lower())\n\nWORDS = Counter(words(open('/kaggle/input/word-corpus-text/big.txt').read()))\n\nWORDS_DICT = dict(WORDS)\n\nfor word in word_corpus_df[\"word\"]:\n    if(word not in WORDS_DICT):\n        WORDS_DICT[word] = 1","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:55:54.057840Z","iopub.execute_input":"2024-02-14T17:55:54.058248Z","iopub.status.idle":"2024-02-14T17:55:55.097688Z","shell.execute_reply.started":"2024-02-14T17:55:54.058213Z","shell.execute_reply":"2024-02-14T17:55:55.096388Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Initializing our sym_spell variable according to the Words Dictionary\nfrom symspellpy import SymSpell, Verbosity\n\nsym_spell = SymSpell()\n\nfor word, word_freq in WORDS_DICT.items():\n    sym_spell.create_dictionary_entry(word, word_freq)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:55:55.100513Z","iopub.execute_input":"2024-02-14T17:55:55.101058Z","iopub.status.idle":"2024-02-14T17:56:13.988447Z","shell.execute_reply.started":"2024-02-14T17:55:55.101020Z","shell.execute_reply":"2024-02-14T17:56:13.987267Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Method to select the best possible word correction using or SymSpell object\ndef correct_spelling_symspell(input_word):\n    \n    if input_word is None:\n        return input_word\n    \n    suggestions = sym_spell.lookup(input_word, Verbosity.CLOSEST, max_edit_distance = 2, include_unknown=True)\n    best_correction = input_word\n    best_correction_freq = -1\n    min_distance = float('inf')\n    for suggestion in suggestions:\n        if(suggestion.term in WORDS_DICT):\n            distance = levenshtein_distance(input_word, suggestion.term)\n            if distance < min_distance:\n                min_distance = distance\n                best_correction = suggestion.term\n                best_correction_freq = WORDS_DICT[suggestion.term]\n            if distance == min_distance:\n                if best_correction_freq < WORDS_DICT[suggestion.term]:\n                    best_correction = suggestion.term\n                    best_correction_freq = WORDS_DICT[suggestion.term]\n    return best_correction","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:56:13.990462Z","iopub.execute_input":"2024-02-14T17:56:13.991008Z","iopub.status.idle":"2024-02-14T17:56:14.001916Z","shell.execute_reply.started":"2024-02-14T17:56:13.990960Z","shell.execute_reply":"2024-02-14T17:56:14.000453Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Applying our SymSpellPy Approach to all 150000 target words\nfrom datetime import datetime\n\nstart_time = datetime.now()\nfor word_index in range(len(words_list_symspellpy)):\n    words_list_symspellpy[word_index] = correct_spelling_symspell(words_list_symspellpy[word_index])\n    \nend_time = datetime.now()\ncounter = int(len(words_list_symspellpy) / 1000)\n    \nprint(words_list_symspellpy[:10])\nprint(\"Average Time to Process 1000 Words: \" + str((end_time - start_time) / counter))","metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:56:14.003559Z","iopub.execute_input":"2024-02-14T17:56:14.003980Z","iopub.status.idle":"2024-02-14T17:57:27.412991Z","shell.execute_reply.started":"2024-02-14T17:56:14.003946Z","shell.execute_reply":"2024-02-14T17:57:27.410856Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"['woodfish', 'dialonian', 'selfheal', 'jadelike', 'communital', 'activital', 'nearliest', 'imprisoning', 'metanotions', 'fainly']\nAverage Time to Process 1000 Words: 0:00:00.489302\n","output_type":"stream"}]},{"cell_type":"code","source":"# Determining the accuracy of SymSpellPy Approach\n\ncorrect_words = 0\nwrong_words = 0\nfor word in words_list_symspellpy:\n    if(word in WORDS_DICT):\n        correct_words = correct_words + 1\n    else:\n        wrong_words = wrong_words + 1\n\nprint(\"Correct Words Percentage: \" + str((correct_words / len(words_list_symspellpy)) * 100))\nprint(\"Wrong Words Percentage: \" + str((wrong_words / len(words_list_symspellpy)) * 100))","metadata":{"execution":{"iopub.status.busy":"2024-02-14T18:01:13.946429Z","iopub.execute_input":"2024-02-14T18:01:13.946956Z","iopub.status.idle":"2024-02-14T18:01:14.066047Z","shell.execute_reply.started":"2024-02-14T18:01:13.946919Z","shell.execute_reply":"2024-02-14T18:01:14.064752Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Correct Words Percentage: 100.0\nWrong Words Percentage: 0.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# BK Tree + Levenshtein Distance Approach","metadata":{}},{"cell_type":"code","source":"# BK Tree class for fast work lookup whilst doing spell checking\nclass BKNode:\n    def __init__(self, word):\n        self.word = word\n        self.children = {}\n\nclass BKTree:\n    def __init__(self):\n        self.root = None\n    \n    # Method to insert the node into the BK Treee\n    def insert(self, word):\n        if not self.root:\n            self.root = BKNode(word)\n            return\n        \n        # According to the levenshtein distance place the word\n        node = self.root\n        distance = levenshtein_distance(word, node.word)\n        while distance in node.children:\n            node = node.children[distance]\n            distance = levenshtein_distance(word, node.word)\n        \n        node.children[distance] = BKNode(word)\n    \n    # Method to get the list of words having a levenshtein distance of 3 from the input_word\n    def query(self, word, max_distance = 3):\n        if not self.root:\n            return []\n\n        result = []\n\n        def _query(node, distance):\n            dist = levenshtein_distance(word, node.word)\n            if dist <= max_distance:\n                result.append((node.word, dist))\n            \n            for d in range(dist - max_distance, dist + max_distance + 1):\n                child = node.children.get(d)\n                if child:\n                    _query(child, max_distance)\n\n        _query(self.root, max_distance)\n        \n        return result","metadata":{"execution":{"iopub.status.busy":"2024-02-14T18:01:29.580034Z","iopub.execute_input":"2024-02-14T18:01:29.580539Z","iopub.status.idle":"2024-02-14T18:01:29.593379Z","shell.execute_reply.started":"2024-02-14T18:01:29.580499Z","shell.execute_reply":"2024-02-14T18:01:29.592197Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Building our BK Tree using the word dictionary\nbk_tree = BKTree()\nfor word, word_freq in WORDS_DICT.items():\n    bk_tree.insert(word)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T18:01:37.858779Z","iopub.execute_input":"2024-02-14T18:01:37.859238Z","iopub.status.idle":"2024-02-14T18:05:57.133462Z","shell.execute_reply.started":"2024-02-14T18:01:37.859205Z","shell.execute_reply":"2024-02-14T18:05:57.132080Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Applying our BK Tree + Levenshtein Distance Approach to all 150000 target words\n\nfrom datetime import datetime\n\nstart_time = datetime.now()\nfor word_index in range(len(words_list_bk_tree)):\n    suggested_corrections = bk_tree.query(words_list_bk_tree[word_index])\n    correct_word = words_list_bk_tree[word_index]\n    correct_word_freq = -1\n    min_dist = 1000\n    for word, ld in suggested_corrections:\n        if(min_dist > ld):\n            min_dist = ld\n            correct_word = word\n            correct_word_freq = WORDS_DICT[correct_word]\n        if(min_dist == ld):\n            if(WORDS_DICT[word] > correct_word_freq):\n                correct_word = word\n                correct_word_freq = WORDS_DICT[correct_word]\n                \n    words_list_bk_tree[word_index] = correct_word\n    \nend_time = datetime.now()\ncounter = int(len(words_list_bk_tree) / 1000)\n    \nprint(\"Average Time to Process 1000 Words: \" + str((end_time - start_time) / counter))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FINAL RESULTS\n\n### symspellpy provides the best spelling correction results at: *0.1 to 0.5 seconds average per 1000 words*","metadata":{}},{"cell_type":"markdown","source":"## References:\n* https://symspellpy.readthedocs.io/en/latest/api/index.html\n* https://norvig.com/spell-correct.html","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}